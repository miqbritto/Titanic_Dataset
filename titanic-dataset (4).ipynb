{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ============================================\n# 1. Importações\n# ============================================\nimport os\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, f1_score\n\n\n# ============================================\n# 2. Verificar arquivos disponíveis no Kaggle\n# ============================================\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n# ============================================\n# 3. Carregar os dados\n# ============================================\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n\n\n# ============================================\n# 4. Preenchimento de dados ausentes\n# ============================================\n# -- Treino\ntrain_data[\"Fare\"] = train_data[\"Fare\"].fillna(train_data[\"Fare\"].mean())\ntrain_data[\"Age\"] = train_data[\"Age\"].fillna(train_data[\"Age\"].mean())\ntrain_data[\"Embarked\"] = train_data[\"Embarked\"].fillna(train_data[\"Embarked\"].mode()[0])\ntrain_data[\"CabinLetter\"] = train_data[\"Cabin\"].str[0].fillna(\"Unknown\")\n\n# -- Teste\ntest_data[\"Fare\"] = test_data[\"Fare\"].fillna(test_data[\"Fare\"].mean())\ntest_data[\"Age\"] = test_data[\"Age\"].fillna(test_data[\"Age\"].mean())\ntest_data[\"Embarked\"] = test_data[\"Embarked\"].fillna(train_data[\"Embarked\"].mode()[0])\ntest_data[\"CabinLetter\"] = test_data[\"Cabin\"].str[0].fillna(\"Unknown\")\n\n\n# ============================================\n# 5. Feature Engineering\n# ============================================\n# -- Treino\ntrain_data[\"FareBin\"] = pd.qcut(train_data[\"Fare\"], 10, labels=False)\ntrain_data[\"AgeBin\"] = pd.cut(train_data[\"Age\"], bins=[0, 12, 18, 35, 60, 80], labels=False)\ntrain_data[\"FamilySize\"] = train_data[\"SibSp\"] + train_data[\"Parch\"] + 1\ntrain_data[\"IsAlone\"] = (train_data[\"FamilySize\"] == 1).astype(int)\ntrain_data[\"FarePerPerson\"] = train_data[\"Fare\"] / train_data[\"FamilySize\"]\ntrain_data[\"ClassFareInteraction\"] = train_data[\"Pclass\"] * train_data[\"Fare\"]\n\n# -- Teste\ntest_data[\"FareBin\"] = pd.qcut(test_data[\"Fare\"], 10, labels=False)\ntest_data[\"AgeBin\"] = pd.cut(test_data[\"Age\"], bins=[0, 12, 18, 35, 60, 80], labels=False)\ntest_data[\"FamilySize\"] = test_data[\"SibSp\"] + test_data[\"Parch\"] + 1\ntest_data[\"IsAlone\"] = (test_data[\"FamilySize\"] == 1).astype(int)\ntest_data[\"FarePerPerson\"] = test_data[\"Fare\"] / test_data[\"FamilySize\"]\ntest_data[\"ClassFareInteraction\"] = test_data[\"Pclass\"] * test_data[\"Fare\"]\n\n\n# ============================================\n# 6. Encoding categórico (OneHotEncoder)\n# ============================================\ncategorical_cols = [\"Sex\", \"Embarked\", \"CabinLetter\", \"IsAlone\"]\nnum_features = [\n    \"Pclass\", \"SibSp\", \"Parch\", \"FareBin\", \"AgeBin\",\n    \"Fare\", \"Age\", \"FamilySize\", \"ClassFareInteraction\", \"FarePerPerson\"\n]\n\n# -- Treino\ncat_encoder = OneHotEncoder(handle_unknown='ignore')\ntrain_data_cat = train_data[categorical_cols]\ntrain_data_cat_1hot = cat_encoder.fit_transform(train_data_cat)\nencoded_train_df = pd.DataFrame(train_data_cat_1hot.toarray(), columns=cat_encoder.get_feature_names_out())\n\ntrain_data_num = train_data[num_features]\ntrain_data_final = pd.concat([train_data_num.reset_index(drop=True), encoded_train_df.reset_index(drop=True)], axis=1)\ny_train = train_data[\"Survived\"].copy()\n\n# -- Teste\ntest_data_cat = test_data[categorical_cols]\ntest_data_cat_1hot = cat_encoder.transform(test_data_cat)\nencoded_test_df = pd.DataFrame(test_data_cat_1hot.toarray(), columns=cat_encoder.get_feature_names_out())\n\ntest_data_num = test_data[num_features]\ntest_data_final = pd.concat([test_data_num.reset_index(drop=True), encoded_test_df.reset_index(drop=True)], axis=1)\n\n\n# ============================================\n# 7. Split para validação local\n# ============================================\nX_train_strat, X_val_strat, y_train_strat, y_val_strat = train_test_split(\n    train_data_final, y_train,\n    test_size=0.2, stratify=y_train, random_state=42\n)\n\n\n# ============================================\n# 8. Modelo\n# ============================================\nrfc = RandomForestClassifier(\n    n_estimators=500,\n    criterion='entropy',\n    max_depth=8,\n    min_samples_split=8,\n    min_samples_leaf=2\n)\n\n\n# ============================================\n# 9. Treino\n# ============================================\nrfc.fit(train_data_final, y_train)\n\n\n# ============================================\n# 10. Predição no conjunto de teste para submissão\n# ============================================\npredictions = rfc.predict(test_data_final)\n\nsubmission = pd.DataFrame({\n    'PassengerId': test_data['PassengerId'],\n    'Survived': predictions\n})\n\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-06T15:38:31.775612Z","iopub.execute_input":"2025-07-06T15:38:31.775911Z","iopub.status.idle":"2025-07-06T15:38:32.773408Z","shell.execute_reply.started":"2025-07-06T15:38:31.775890Z","shell.execute_reply":"2025-07-06T15:38:32.772687Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}],"execution_count":55}]}